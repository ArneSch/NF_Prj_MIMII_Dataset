{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Structure-cheat-sheet\" data-toc-modified-id=\"Structure-cheat-sheet-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Structure cheat sheet</a></span></li><li><span><a href=\"#Data-structure\" data-toc-modified-id=\"Data-structure-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data structure</a></span></li><li><span><a href=\"#get-features\" data-toc-modified-id=\"get-features-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>get features</a></span></li><li><span><a href=\"#Exploration-of-non-spectral-Features\" data-toc-modified-id=\"Exploration-of-non-spectral-Features-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Exploration of non-spectral Features</a></span></li><li><span><a href=\"#Exploring-spectral-features\" data-toc-modified-id=\"Exploring-spectral-features-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Exploring spectral features</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics\n",
    "\n",
    "## Structure cheat sheet\n",
    "\n",
    "1. func: train data lead (following order)\n",
    "    1. read the descriptive dataframe from the feature-pipeline\n",
    "    2. extract feature from the feature-objects which are labeled train-dataset from dataframe\n",
    "    3. create numpy feature array for the processing pipeline\n",
    "2. preprocessing\n",
    "    1. Transformation (any combination of the following)\n",
    "        + log-transform\n",
    "        + PCA\n",
    "        + others\n",
    "    2. Scaling (one of the following)\n",
    "        + StandardScaler\n",
    "        + MinMaxScaler\n",
    "3. Unsupervised Clustering\n",
    "    1. Estimate initial hyperparameter\n",
    "    2. Create grid over various hyperparameters\n",
    "    3. Train all and choose the best according to metric\n",
    "    \n",
    "    \n",
    "in all steps the cluster-recorder object (possibly dataframe-row) will record all the meta-information like hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data structure\n",
    "\n",
    "There are multiple degrees of freedom in the data:\n",
    "\n",
    "1. Signal to noise ratio (SNR)\n",
    "2. Machine type\n",
    "    1. pump\n",
    "    2. fan\n",
    "    3. valve (solenoid)\n",
    "    4. slider\n",
    "3. Machine ID\n",
    "    1. four different machine IDs\n",
    "    \n",
    "The pipeline will be applied to fixed SNR, fixed machine type and fixed ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get features\n",
    "\n",
    "Get the descriptive dataframe for the features.\n",
    "\n",
    "The descriptive dataframe contains all IDs of the pump. We will focus on ID '00' for now since the modeling phase is seperated per SNR, per machine, per ID anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class: \n",
    "+ uni\\_\\<model\\>\n",
    "attributes:\n",
    "+ default threshold\n",
    "+ roc_auc\n",
    "methods:\n",
    "+ fit\n",
    "+ predict\n",
    "+ predict_score\n",
    "+ eval_roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T13:57:46.428644Z",
     "start_time": "2020-05-11T13:57:34.152820Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load feature_extractor_mother\n",
      "load feature_extractor_mel_spectra\n",
      "load feature_extractor_psd\n",
      "load feature_extractor_ICA2\n",
      "load feature_extractore_pre_nnFilterDenoise\n",
      "load extractor_diagram_mother\n",
      "load Simple_FIR_HP\n",
      "load TimeSliceAppendActivation\n",
      "load load_data\n",
      "Load split_data\n",
      "Load anomaly_detection_models\n",
      "Load pseudo_supervised_models\n",
      "Load tensorflow models\n",
      "Load detection_pipe\n"
     ]
    }
   ],
   "source": [
    "#===============================================\n",
    "# Basic Imports\n",
    "BASE_FOLDER = '../../'\n",
    "%run -i ..\\..\\utility\\feature_extractor\\JupyterLoad_feature_extractor.py\n",
    "%run -i ..\\..\\utility\\modeling\\JupyterLoad_modeling.py\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from tqdm.auto import tqdm\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exploration of the Dimensionality Reduction was already done in another notebook. We derived the following rules of thumb:\n",
    "\n",
    "1. PCA and ICA deliver almost the same results looking at the relative absolute error\n",
    "2. PCA is usually much faster\n",
    "3. on PSD and the ICA demix matrix, no dimensionality reduction is needed\n",
    "4. for a framed Mel-spectrum a number of components between 32 and 64 is a good measure. The resulting error is about 2-4%\n",
    "5. for a whole Mel-spectrum a number of components between 64 and 128 is advised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration of non-spectral Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring spectral features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T15:27:28.139383Z",
     "start_time": "2020-05-11T15:27:28.082383Z"
    },
    "code_folding": [
     6,
     10,
     26
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagram = 'extdia_v1'\n",
    "machines = ['pump', 'fan', 'slider', 'valve'\n",
    "]\n",
    "SNRs = ['6dB', 'min6dB']\n",
    "IDs = [#'00', '02', \n",
    "    '04', '06']\n",
    "\n",
    "features = [('MEL_den', {'function':'frame', 'frames':5})\n",
    "            #, ('PSD_raw', {'function':'channel'})\n",
    "            ]\n",
    "\n",
    "tasks = [{\n",
    "        'path_descr':glob.glob(BASE_FOLDER \n",
    "                            + '/dataset/extdia_v1*/{}{}{}_EDiaV1'.format(machine, SNR, ID) \n",
    "                            + \"*pandaDisc*.pkl\", recursive=True)[-1],\n",
    "        'feat':feature[1], \n",
    "        'feat_col':feature[0], \n",
    "        'SNR':SNR, \n",
    "        'machine':machine, \n",
    "        'ID':ID,\n",
    "        'BASE_FOLDER':BASE_FOLDER}\n",
    "        for machine in machines\n",
    "        for SNR in SNRs\n",
    "        for ID in IDs\n",
    "        for feature in features\n",
    "        ]\n",
    "\n",
    "preprocessing = [\n",
    "    (PCA, {'n_components':64}),\n",
    "    (StandardScaler, {})\n",
    "]\n",
    "\n",
    "modeling = (uni_AutoEncoder, {'epochs':50})\n",
    "\n",
    "pipes = [Pipe(preprocessing, modeling) for i in range(len(features)*len(IDs)*len(machines)*len(SNRs))]\n",
    "len(pipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T15:27:32.295488Z",
     "start_time": "2020-05-11T15:27:32.239489Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [('MEL_den', {'function':'frame', 'frames':5})]\n",
    "\n",
    "tasks += [{\n",
    "        'path_descr':glob.glob(BASE_FOLDER \n",
    "                            + '/dataset/extdia_v1*/{}{}{}_EDiaV1'.format(machine, SNR, ID) \n",
    "                            + \"*pandaDisc*.pkl\", recursive=True)[-1],\n",
    "        'feat':feature[1], \n",
    "        'feat_col':feature[0], \n",
    "        'SNR':SNR, \n",
    "        'machine':machine, \n",
    "        'ID':ID,\n",
    "        'BASE_FOLDER':BASE_FOLDER}\n",
    "        for machine in machines\n",
    "        for SNR in SNRs\n",
    "        for ID in IDs\n",
    "        for feature in features\n",
    "        ]\n",
    "\n",
    "preprocessing = [\n",
    "    (PCA, {'n_components':64}),\n",
    "    (StandardScaler, {})\n",
    "]\n",
    "\n",
    "modeling = (uni_IsolationForest, {'n_estimators':64, 'max_features':4})\n",
    "\n",
    "pipes += [Pipe(preprocessing, modeling) for i in range(len(features)*len(IDs)*len(machines)*len(SNRs))]\n",
    "len(pipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T15:27:36.574910Z",
     "start_time": "2020-05-11T15:27:36.528910Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [('PSD_raw', {'function':'channel'})]\n",
    "\n",
    "tasks += [{\n",
    "        'path_descr':glob.glob(BASE_FOLDER \n",
    "                            + '/dataset/extdia_v1*/{}{}{}_EDiaV1'.format(machine, SNR, ID) \n",
    "                            + \"*pandaDisc*.pkl\", recursive=True)[-1],\n",
    "        'feat':feature[1], \n",
    "        'feat_col':feature[0], \n",
    "        'SNR':SNR, \n",
    "        'machine':machine, \n",
    "        'ID':ID,\n",
    "        'BASE_FOLDER':BASE_FOLDER}\n",
    "        for machine in machines\n",
    "        for SNR in SNRs\n",
    "        for ID in IDs\n",
    "        for feature in features\n",
    "        ]\n",
    "\n",
    "preprocessing = [\n",
    "    (PCA, {'n_components':64}),\n",
    "    (StandardScaler, {})\n",
    "]\n",
    "\n",
    "modeling = (uni_IsolationForest, {'n_estimators':200, 'max_features':1})\n",
    "\n",
    "pipes += [Pipe(preprocessing, modeling) for i in range(len(features)*len(IDs)*len(machines)*len(SNRs))]\n",
    "len(pipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T15:35:17.452556Z",
     "start_time": "2020-05-11T15:34:52.148808Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc75e7828714ac89db49d6426ffedc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=16.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../..//dataset\\extdia_v1\\pump6dB04_EDiaV1HP_pandaDisc.pkl --> Done\n",
      "...loading data\n",
      "data loading completed\n",
      "\n",
      "...preprocessing data\n",
      "data preprocessing finished\n",
      "\n",
      "...fitting the model\n",
      "model fitted successfully\n",
      "\n",
      "...evaluating model\n",
      "evaluation successfull, roc_auc: 0.994\n",
      "pipe saved to pickle\n",
      "../..//dataset\\extdia_v1\\pump6dB06_EDiaV1HP_pandaDisc.pkl --> Done\n",
      "...loading data\n",
      "data loading completed\n",
      "\n",
      "...preprocessing data\n",
      "data preprocessing finished\n",
      "\n",
      "...fitting the model\n",
      "model fitted successfully\n",
      "\n",
      "...evaluating model\n",
      "evaluation successfull, roc_auc: 0.9765474817377932\n",
      "pipe saved to pickle\n",
      "../..//dataset\\extdia_v1\\pumpmin6dB04_EDiaV1HP_pandaDisc.pkl --> Done\n",
      "...loading data\n",
      "data loading completed\n",
      "\n",
      "...preprocessing data\n",
      "data preprocessing finished\n",
      "\n",
      "...fitting the model\n",
      "model fitted successfully\n",
      "\n",
      "...evaluating model\n",
      "evaluation successfull, roc_auc: 0.7591\n",
      "pipe saved to pickle\n",
      "../..//dataset\\extdia_v1\\pumpmin6dB06_EDiaV1HP_pandaDisc.pkl --> Done\n",
      "...loading data\n",
      "data loading completed\n",
      "\n",
      "...preprocessing data\n",
      "data preprocessing finished\n",
      "\n",
      "...fitting the model\n",
      "model fitted successfully\n",
      "\n",
      "...evaluating model\n",
      "evaluation successfull, roc_auc: 0.7841214917339485\n",
      "pipe saved to pickle\n",
      "../..//dataset\\extdia_v1\\fan6dB04_EDiaV1HP_pandaDisc.pkl --> Done\n",
      "...loading data\n",
      "data loading completed\n",
      "\n",
      "...preprocessing data\n",
      "data preprocessing finished\n",
      "\n",
      "...fitting the model\n",
      "model fitted successfully\n",
      "\n",
      "...evaluating model\n",
      "evaluation successfull, roc_auc: 0.9893975426080063\n",
      "pipe saved to pickle\n",
      "../..//dataset\\extdia_v1\\fan6dB06_EDiaV1HP_pandaDisc.pkl --> Done\n",
      "...loading data\n",
      "data loading completed\n",
      "\n",
      "...preprocessing data\n",
      "data preprocessing finished\n",
      "\n",
      "...fitting the model\n",
      "model fitted successfully\n",
      "\n",
      "...evaluating model\n",
      "evaluation successfull, roc_auc: 0.9919736650271254\n",
      "pipe saved to pickle\n",
      "../..//dataset\\extdia_v1\\fanmin6dB04_EDiaV1HP_pandaDisc.pkl --> Done\n",
      "...loading data\n",
      "data loading completed\n",
      "\n",
      "...preprocessing data\n",
      "data preprocessing finished\n",
      "\n",
      "...fitting the model\n",
      "model fitted successfully\n",
      "\n",
      "...evaluating model\n",
      "evaluation successfull, roc_auc: 0.6141085348130533\n",
      "pipe saved to pickle\n",
      "../..//dataset\\extdia_v1\\fanmin6dB06_EDiaV1HP_pandaDisc.pkl --> Done\n",
      "...loading data\n",
      "data loading completed\n",
      "\n",
      "...preprocessing data\n",
      "data preprocessing finished\n",
      "\n",
      "...fitting the model\n",
      "model fitted successfully\n",
      "\n",
      "...evaluating model\n",
      "evaluation successfull, roc_auc: 0.9331113174392464\n",
      "pipe saved to pickle\n",
      "../..//dataset\\extdia_v1\\slider6dB04_EDiaV1HP_pandaDisc.pkl --> Done\n",
      "...loading data\n",
      "data loading completed\n",
      "\n",
      "...preprocessing data\n",
      "data preprocessing finished\n",
      "\n",
      "...fitting the model\n",
      "model fitted successfully\n",
      "\n",
      "...evaluating model\n",
      "evaluation successfull, roc_auc: 0.9974750662795102\n",
      "pipe saved to pickle\n",
      "../..//dataset\\extdia_v1\\slider6dB06_EDiaV1HP_pandaDisc.pkl --> Done\n",
      "...loading data\n",
      "data loading completed\n",
      "\n",
      "...preprocessing data\n",
      "data preprocessing finished\n",
      "\n",
      "...fitting the model\n",
      "model fitted successfully\n",
      "\n",
      "...evaluating model\n",
      "evaluation successfull, roc_auc: 0.993308925640702\n",
      "pipe saved to pickle\n",
      "../..//dataset\\extdia_v1\\slidermin6dB04_EDiaV1HP_pandaDisc.pkl --> Done\n",
      "...loading data\n",
      "data loading completed\n",
      "\n",
      "...preprocessing data\n",
      "data preprocessing finished\n",
      "\n",
      "...fitting the model\n",
      "model fitted successfully\n",
      "\n",
      "...evaluating model\n",
      "evaluation successfull, roc_auc: 0.6327168286832471\n",
      "pipe saved to pickle\n",
      "../..//dataset\\extdia_v1\\slidermin6dB06_EDiaV1HP_pandaDisc.pkl --> Done\n",
      "...loading data\n",
      "data loading completed\n",
      "\n",
      "...preprocessing data\n",
      "data preprocessing finished\n",
      "\n",
      "...fitting the model\n",
      "model fitted successfully\n",
      "\n",
      "...evaluating model\n",
      "evaluation successfull, roc_auc: 0.5851533897235197\n",
      "pipe saved to pickle\n",
      "../..//dataset\\extdia_v1_sporafic\\valve6dB04_EDiaV1HPaug0TsSl_pandaDisc.pkl --> Done\n",
      "...loading data\n",
      "data loading completed\n",
      "\n",
      "...preprocessing data\n",
      "data preprocessing finished\n",
      "\n",
      "...fitting the model\n",
      "model fitted successfully\n",
      "\n",
      "...evaluating model\n",
      "evaluation successfull, roc_auc: 0.9531944444444445\n",
      "pipe saved to pickle\n",
      "../..//dataset\\extdia_v1_sporafic\\valve6dB06_EDiaV1HPaug0TsSl_pandaDisc.pkl --> Done\n",
      "...loading data\n",
      "data loading completed\n",
      "\n",
      "...preprocessing data\n",
      "data preprocessing finished\n",
      "\n",
      "...fitting the model\n",
      "model fitted successfully\n",
      "\n",
      "...evaluating model\n",
      "evaluation successfull, roc_auc: 0.5802777777777778\n",
      "pipe saved to pickle\n",
      "../..//dataset\\extdia_v1_sporafic\\valvemin6dB04_EDiaV1HPaug0TsSl_pandaDisc.pkl --> Done\n",
      "...loading data\n",
      "data loading completed\n",
      "\n",
      "...preprocessing data\n",
      "data preprocessing finished\n",
      "\n",
      "...fitting the model\n",
      "model fitted successfully\n",
      "\n",
      "...evaluating model\n",
      "evaluation successfull, roc_auc: 0.7854166666666667\n",
      "pipe saved to pickle\n",
      "../..//dataset\\extdia_v1_sporafic\\valvemin6dB06_EDiaV1HPaug0TsSl_pandaDisc.pkl --> Done\n",
      "...loading data\n",
      "data loading completed\n",
      "\n",
      "...preprocessing data\n",
      "data preprocessing finished\n",
      "\n",
      "...fitting the model\n",
      "model fitted successfully\n",
      "\n",
      "...evaluating model\n",
      "evaluation successfull, roc_auc: 0.5615972222222222\n",
      "pipe saved to pickle\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#failed = [12:16] + [28:32]\n",
    "start = 32\n",
    "for pipe, task in tqdm(zip(pipes[12:16] + pipes[28:32], tasks[12:16] + tasks[28:32]), total=len(tasks[12:16] + tasks[28:32])):\n",
    "    pipe.run_pipe(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3.7 (mimii_base_TF2_GPU)",
   "language": "python",
   "name": "mimii-tf2-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
