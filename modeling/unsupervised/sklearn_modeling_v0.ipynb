{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Structure-cheat-sheet\" data-toc-modified-id=\"Structure-cheat-sheet-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Structure cheat sheet</a></span></li><li><span><a href=\"#Data-structure\" data-toc-modified-id=\"Data-structure-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data structure</a></span></li><li><span><a href=\"#get-features\" data-toc-modified-id=\"get-features-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>get features</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics\n",
    "\n",
    "## Structure cheat sheet\n",
    "\n",
    "1. func: train data lead (following order)\n",
    "    1. read the descriptive dataframe from the feature-pipeline\n",
    "    2. extract feature from the feature-objects which are labeled train-dataset from dataframe\n",
    "    3. create numpy feature array for the processing pipeline\n",
    "2. preprocessing\n",
    "    1. Transformation (any combination of the following)\n",
    "        + log-transform\n",
    "        + PCA\n",
    "        + others\n",
    "    2. Scaling (one of the following)\n",
    "        + StandardScaler\n",
    "        + MinMaxScaler\n",
    "3. Unsupervised Clustering\n",
    "    1. Estimate initial hyperparameter\n",
    "    2. Create grid over various hyperparameters\n",
    "    3. Train all and choose the best according to metric\n",
    "    \n",
    "    \n",
    "in all steps the cluster-recorder object (possibly dataframe-row) will record all the meta-information like hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data structure\n",
    "\n",
    "There are multiple degrees of freedom in the data:\n",
    "\n",
    "1. Signal to noise ratio (SNR)\n",
    "2. Machine type\n",
    "    1. pump\n",
    "    2. fan\n",
    "    3. valve (solenoid)\n",
    "    4. slider\n",
    "3. Machine ID\n",
    "    1. four different machine IDs\n",
    "    \n",
    "The pipeline will be applied to fixed SNR, fixed machine type and fixed ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get features\n",
    "\n",
    "Get the descriptive dataframe for the features.\n",
    "\n",
    "The descriptive dataframe contains all IDs of the pump. We will focus on ID '00' for now since the modeling phase is seperated per SNR, per machine, per ID anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class: \n",
    "+ uni\\_\\<model\\>\n",
    "attributes:\n",
    "+ default threshold\n",
    "+ roc_auc\n",
    "methods:\n",
    "+ fit\n",
    "+ predict\n",
    "+ predict_score\n",
    "+ eval_roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T11:47:44.347174Z",
     "start_time": "2020-04-30T11:47:41.047370Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "load feature_extractor_mother\nload feature_extractor_mel_spectra\nload feature_extractor_psd\nload feature_extractore_pre_nnFilterDenoise\nload extractor_diagram_mother\nload load_data\nLoad split_data\nLoad anomaly_detection_models\nLoad detection_pipe\n"
    }
   ],
   "source": [
    "#===============================================\n",
    "# Basic Imports\n",
    "\n",
    "\n",
    "BASE_FOLDER = '../../'\n",
    "%run -i ..\\..\\utility\\feature_extractor\\JupyterLoad_feature_extractor.py\n",
    "%run -i ..\\..\\utility\\modeling\\JupyterLoad_modeling.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T11:47:44.362176Z",
     "start_time": "2020-04-30T11:47:44.349176Z"
    }
   },
   "outputs": [],
   "source": [
    "diagrams = ['extdia_v1']\n",
    "machines = ['pump'#, 'fan', 'slider'\n",
    "            , 'valve'\n",
    "            ]\n",
    "SNRs = ['6dB', 'min6dB'\n",
    "        ]\n",
    "IDs = ['00',# '02', '04', '06'\n",
    "        ]\n",
    "features = ['MEL_denbssm', 'PSD_denbssm', 'MEL_bssm', 'PSD_bssm', 'MEL_raw', 'PSD_raw', 'MEL_den', 'PSD_den', 'ICA_demix'\n",
    "            ]\n",
    "\n",
    "tasks = [{\n",
    "        'path_descr':BASE_FOLDER + 'dataset/{}/{}{}{}_EDiaV1_pandaDisc.pkl'.format(diagram, machine, SNR, ID), \n",
    "        'feat':{'function':'frame', 'frames':3}, \n",
    "        'feat_col':feature, \n",
    "        'SNR':SNR, \n",
    "        'machine':machine, \n",
    "        'ID':ID,\n",
    "        'BASE_FOLDER':BASE_FOLDER} \n",
    "        for diagram in diagrams\n",
    "        for machine in machines\n",
    "        for SNR in SNRs\n",
    "        for ID in IDs\n",
    "        for feature in features\n",
    "        ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "\n",
    "preprocessing = [\n",
    "    (FastICA, {'n_components':40, 'algorithm':'parallel'}),\n",
    "    (StandardScaler, {})\n",
    "]\n",
    "\n",
    "modeling = (uni_EllipticEnvelope, {'random_state':42})\n",
    "\n",
    "pipes = [Pipe(preprocessing, modeling) for i in range(len(tasks))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T11:47:44.406174Z",
     "start_time": "2020-04-30T11:47:44.386174Z"
    }
   },
   "outputs": [],
   "source": [
    "#lw = LoggerWrap()\n",
    "\n",
    "# create the threads\n",
    "n_jobs = 4\n",
    "worker_list = []\n",
    "queue = Queue()\n",
    "for worker in range(n_jobs):\n",
    "    worker = PipeThread(queue)\n",
    "    worker.daemon = True\n",
    "    worker.start()\n",
    "    worker_list.append(worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T11:47:44.428178Z",
     "start_time": "2020-04-30T11:47:44.409175Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "...loading data\ndata loading completed\n\n...preprocessing data\n"
    }
   ],
   "source": [
    "# fill the Queue\n",
    "#lw.log('multithread mode filling the queue' )\n",
    "for pipe, task in (zip(pipes, tasks)):\n",
    "    queue.put((pipe, task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T11:46:24.954418Z",
     "start_time": "2020-04-30T11:46:24.871418Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for worker in worker_list:\n",
    "    worker.stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3.7 (mimii_base_TF2_GPU)",
   "language": "python",
   "name": "mimii-tf2-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}