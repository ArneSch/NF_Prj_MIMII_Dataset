{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Structure-cheat-sheet\" data-toc-modified-id=\"Structure-cheat-sheet-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Structure cheat sheet</a></span></li><li><span><a href=\"#Data-structure\" data-toc-modified-id=\"Data-structure-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data structure</a></span></li><li><span><a href=\"#get-features\" data-toc-modified-id=\"get-features-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>get features</a></span></li><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Scaling\" data-toc-modified-id=\"Scaling-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Scaling</a></span></li><li><span><a href=\"#PCA\" data-toc-modified-id=\"PCA-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>PCA</a></span></li></ul></li><li><span><a href=\"#Unsupervised-Clustering\" data-toc-modified-id=\"Unsupervised-Clustering-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Unsupervised Clustering</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics\n",
    "\n",
    "## Structure cheat sheet\n",
    "\n",
    "1. func: train data lead (following order)\n",
    "    1. read the descriptive dataframe from the feature-pipeline\n",
    "    2. extract feature from the feature-objects which are labeled train-dataset from dataframe\n",
    "    3. create numpy feature array for the processing pipeline\n",
    "2. preprocessing\n",
    "    1. Transformation (any combination of the following)\n",
    "        + log-transform\n",
    "        + PCA\n",
    "        + others\n",
    "    2. Scaling (one of the following)\n",
    "        + StandardScaler\n",
    "        + MinMaxScaler\n",
    "3. Unsupervised Clustering\n",
    "    1. Estimate initial hyperparameter\n",
    "    2. Create grid over various hyperparameters\n",
    "    3. Train all and choose the best according to metric\n",
    "    \n",
    "    \n",
    "in all steps the cluster-recorder object (possibly dataframe-row) will record all the meta-information like hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple degrees of freedom in the data:\n",
    "\n",
    "1. Signal to noise ratio (SNR)\n",
    "2. Machine type\n",
    "    1. pump\n",
    "    2. fan\n",
    "    3. valve (solenoid)\n",
    "    4. slider\n",
    "3. Machine ID\n",
    "    1. four different machine IDs\n",
    "    \n",
    "The pipeline will be applied to fixed SNR, fixed machine type and fixed ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T09:59:41.361406Z",
     "start_time": "2020-04-27T09:59:41.327406Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "load feature_extractor_mother\nload feature_extractor_mel_spectra\nload feature_extractor_psd\nload feature_extractore_pre_nnFilterDenoise\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "sns.set()\n",
    "\n",
    "BASE_FOLDER = '../../'\n",
    "%run -i ..\\..\\utility\\feature_extractor\\JupyterLoad_feature_extractor.py\n",
    "%run -i ..\\..\\utility\\modeling\\JupyterLoad_modeling.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the descriptive dataframe for the features.\n",
    "\n",
    "The descriptive dataframe contains all IDs of the pump. We will focus on ID '00' for now since the modeling phase is seperated per SNR, per machine, per ID anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T10:00:48.580925Z",
     "start_time": "2020-04-27T09:59:44.500405Z"
    },
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 863/863 [00:01<00:00, 636.04it/s]\n"
    }
   ],
   "source": [
    "path_descr = '.\\..\\..\\dataset\\MEL_to_Pandas\\data_6dB_pump\\FEpandas_MELv1_nm80_ch0.pkl'\n",
    "ID = '00'\n",
    "# loading time feature extractor: 4:37\n",
    "if ('df_train' in dir()) and ('data_train' in dir()):\n",
    "    pass\n",
    "else:\n",
    "    df_descr, data_train = load_data(path_descr, feat={'function':'frame', 'frames':5}, feat_col='MELv1_nm80_ch0', SNR='6dB', machine='pump', ID='00', train_set=True, BASE_FOLDER=BASE_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(266667, 400)"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(266667, 10)"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                    path abnormal  ID  \\\n0      d:\\Capstone\\NF_Prj_MIMII_Dataset\\dataset\\6dB\\p...        0  00   \n1      d:\\Capstone\\NF_Prj_MIMII_Dataset\\dataset\\6dB\\p...        0  00   \n2      d:\\Capstone\\NF_Prj_MIMII_Dataset\\dataset\\6dB\\p...        0  00   \n3      d:\\Capstone\\NF_Prj_MIMII_Dataset\\dataset\\6dB\\p...        0  00   \n4      d:\\Capstone\\NF_Prj_MIMII_Dataset\\dataset\\6dB\\p...        0  00   \n...                                                  ...      ...  ..   \n88369  d:\\Capstone\\NF_Prj_MIMII_Dataset\\dataset\\6dB\\p...        1  00   \n88370  d:\\Capstone\\NF_Prj_MIMII_Dataset\\dataset\\6dB\\p...        1  00   \n88371  d:\\Capstone\\NF_Prj_MIMII_Dataset\\dataset\\6dB\\p...        1  00   \n88372  d:\\Capstone\\NF_Prj_MIMII_Dataset\\dataset\\6dB\\p...        1  00   \n88373  d:\\Capstone\\NF_Prj_MIMII_Dataset\\dataset\\6dB\\p...        1  00   \n\n           file machine  SNR  \\\n0      00000011    pump  6dB   \n1      00000011    pump  6dB   \n2      00000011    pump  6dB   \n3      00000011    pump  6dB   \n4      00000011    pump  6dB   \n...         ...     ...  ...   \n88369  00000142    pump  6dB   \n88370  00000142    pump  6dB   \n88371  00000142    pump  6dB   \n88372  00000142    pump  6dB   \n88373  00000142    pump  6dB   \n\n                                          MELv1_nm80_ch0  train_set  file_idx  \\\n0      \\dataset\\MEL_to_Pandas\\data_6dB_pump\\MELv1_nm8...          0        11   \n1      \\dataset\\MEL_to_Pandas\\data_6dB_pump\\MELv1_nm8...          0        11   \n2      \\dataset\\MEL_to_Pandas\\data_6dB_pump\\MELv1_nm8...          0        11   \n3      \\dataset\\MEL_to_Pandas\\data_6dB_pump\\MELv1_nm8...          0        11   \n4      \\dataset\\MEL_to_Pandas\\data_6dB_pump\\MELv1_nm8...          0        11   \n...                                                  ...        ...       ...   \n88369  \\dataset\\MEL_to_Pandas\\data_6dB_pump\\MELv1_nm8...          0      1148   \n88370  \\dataset\\MEL_to_Pandas\\data_6dB_pump\\MELv1_nm8...          0      1148   \n88371  \\dataset\\MEL_to_Pandas\\data_6dB_pump\\MELv1_nm8...          0      1148   \n88372  \\dataset\\MEL_to_Pandas\\data_6dB_pump\\MELv1_nm8...          0      1148   \n88373  \\dataset\\MEL_to_Pandas\\data_6dB_pump\\MELv1_nm8...          0      1148   \n\n       frame  \n0          0  \n1          1  \n2          2  \n3          3  \n4          4  \n...      ...  \n88369    304  \n88370    305  \n88371    306  \n88372    307  \n88373    308  \n\n[88374 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>abnormal</th>\n      <th>ID</th>\n      <th>file</th>\n      <th>machine</th>\n      <th>SNR</th>\n      <th>MELv1_nm80_ch0</th>\n      <th>train_set</th>\n      <th>file_idx</th>\n      <th>frame</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>d:\\Capstone\\NF_Prj_MIMII_Dataset\\dataset\\6dB\\p...</td>\n      <td>0</td>\n      <td>00</td>\n      <td>00000011</td>\n      <td>pump</td>\n      <td>6dB</td>\n      <td>\\dataset\\MEL_to_Pandas\\data_6dB_pump\\MELv1_nm8...</td>\n      <td>0</td>\n      <td>11</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>d:\\Capstone\\NF_Prj_MIMII_Dataset\\dataset\\6dB\\p...</td>\n      <td>0</td>\n      <td>00</td>\n      <td>00000011</td>\n      <td>pump</td>\n      <td>6dB</td>\n      <td>\\dataset\\MEL_to_Pandas\\data_6dB_pump\\MELv1_nm8...</td>\n      <td>0</td>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>d:\\Capstone\\NF_Prj_MIMII_Dataset\\dataset\\6dB\\p...</td>\n      <td>0</td>\n      <td>00</td>\n      <td>00000011</td>\n      <td>pump</td>\n      <td>6dB</td>\n      <td>\\dataset\\MEL_to_Pandas\\data_6dB_pump\\MELv1_nm8...</td>\n      <td>0</td>\n      <td>11</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>d:\\Capstone\\NF_Prj_MIMII_Dataset\\dataset\\6dB\\p...</td>\n      <td>0</td>\n      <td>00</td>\n      <td>00000011</td>\n      <td>pump</td>\n      <td>6dB</td>\n      <td>\\dataset\\MEL_to_Pandas\\data_6dB_pump\\MELv1_nm8...</td>\n      <td>0</td>\n      <td>11</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>d:\\Capstone\\NF_Prj_MIMII_Dataset\\dataset\\6dB\\p...</td>\n      <td>0</td>\n      <td>00</td>\n      <td>00000011</td>\n      <td>pump</td>\n      <td>6dB</td>\n      <td>\\dataset\\MEL_to_Pandas\\data_6dB_pump\\MELv1_nm8...</td>\n      <td>0</td>\n      <td>11</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>88369</th>\n      <td>d:\\Capstone\\NF_Prj_MIMII_Dataset\\dataset\\6dB\\p...</td>\n      <td>1</td>\n      <td>00</td>\n      <td>00000142</td>\n      <td>pump</td>\n      <td>6dB</td>\n      <td>\\dataset\\MEL_to_Pandas\\data_6dB_pump\\MELv1_nm8...</td>\n      <td>0</td>\n      <td>1148</td>\n      <td>304</td>\n    </tr>\n    <tr>\n      <th>88370</th>\n      <td>d:\\Capstone\\NF_Prj_MIMII_Dataset\\dataset\\6dB\\p...</td>\n      <td>1</td>\n      <td>00</td>\n      <td>00000142</td>\n      <td>pump</td>\n      <td>6dB</td>\n      <td>\\dataset\\MEL_to_Pandas\\data_6dB_pump\\MELv1_nm8...</td>\n      <td>0</td>\n      <td>1148</td>\n      <td>305</td>\n    </tr>\n    <tr>\n      <th>88371</th>\n      <td>d:\\Capstone\\NF_Prj_MIMII_Dataset\\dataset\\6dB\\p...</td>\n      <td>1</td>\n      <td>00</td>\n      <td>00000142</td>\n      <td>pump</td>\n      <td>6dB</td>\n      <td>\\dataset\\MEL_to_Pandas\\data_6dB_pump\\MELv1_nm8...</td>\n      <td>0</td>\n      <td>1148</td>\n      <td>306</td>\n    </tr>\n    <tr>\n      <th>88372</th>\n      <td>d:\\Capstone\\NF_Prj_MIMII_Dataset\\dataset\\6dB\\p...</td>\n      <td>1</td>\n      <td>00</td>\n      <td>00000142</td>\n      <td>pump</td>\n      <td>6dB</td>\n      <td>\\dataset\\MEL_to_Pandas\\data_6dB_pump\\MELv1_nm8...</td>\n      <td>0</td>\n      <td>1148</td>\n      <td>307</td>\n    </tr>\n    <tr>\n      <th>88373</th>\n      <td>d:\\Capstone\\NF_Prj_MIMII_Dataset\\dataset\\6dB\\p...</td>\n      <td>1</td>\n      <td>00</td>\n      <td>00000142</td>\n      <td>pump</td>\n      <td>6dB</td>\n      <td>\\dataset\\MEL_to_Pandas\\data_6dB_pump\\MELv1_nm8...</td>\n      <td>0</td>\n      <td>1148</td>\n      <td>308</td>\n    </tr>\n  </tbody>\n</table>\n<p>88374 rows × 10 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_descr = '.\\..\\..\\dataset\\MEL_to_Pandas\\data_6dB_pump\\FEpandas_MELv1_nm80_ch0.pkl'\n",
    "ID = '00'\n",
    "# loading time feature extractor: 4:37\n",
    "if ('df_test' in dir()) and ('data_test' in dir()):\n",
    "    pass\n",
    "else:\n",
    "    df_test, data_test = load_data(path_descr, feat={'function':'frame', 'frames':5}, feat_col='MELv1_nm80_ch0', SNR='6dB', machine='pump', ID='00', train_set=False, BASE_FOLDER=BASE_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T10:00:51.599923Z",
     "start_time": "2020-04-27T10:00:50.445924Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_train = scaler.fit_transform(data_train)\n",
    "data_test = scaler.transform(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA/ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T10:00:59.079923Z",
     "start_time": "2020-04-27T10:00:51.603930Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, FastICA\n",
    "\n",
    "# instantiate pca\n",
    "n_comp = 40\n",
    "#xca = PCA(n_components=n_comp, svd_solver='full')\n",
    "xca = FastICA(n_components=n_comp, algorithm='parallel')\n",
    "\n",
    "data_train = xca.fit_transform(data_train)\n",
    "data_test = xca.transform(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.covariance import EllipticEnvelope\n",
    "\n",
    "cov = EllipticEnvelope(random_state = 0).fit(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([-1,  1])"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "# Now we can use predict method. It will return 1 for an inlier and -1 for an outlier.\n",
    "y_pred = cov.predict(data_test)\n",
    "y_pred\n",
    "np.unique(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[31528, 12659],\n       [ 4272, 39915]], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, roc_auc_score\n",
    "\n",
    "y_true = [1 if i==0 else -1 for i in df_test.abnormal.astype(np.int8)]\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_curve(y_true, cov.predict(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred == y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = cov.get_precision()\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "y_true = [1 if i==-1 else 0 for i in prediction]]\n",
    "\n",
    "roc_curve(, cov.decision_function(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov.decision_function(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example settings\n",
    "n_samples = 200\n",
    "outliers_fraction = 0.25\n",
    "clusters_separation = [0, 1, 2]\n",
    "\n",
    "# define two outlier detection tools to be compared\n",
    "classifiers = {\n",
    "    \"One-Class SVM\": svm.OneClassSVM(nu=0.95 * outliers_fraction + 0.05,\n",
    "                                     kernel=\"rbf\", gamma=0.1),\n",
    "    \"Robust covariance\": EllipticEnvelope(contamination=outliers_fraction),\n",
    "    \"Isolation Forest\": IsolationForest(max_samples=n_samples,\n",
    "                                        contamination=outliers_fraction,\n",
    "                                        random_state=rng)}\n",
    "\n",
    "for i, (clf_name, clf) in enumerate(classifiers.items()):\n",
    "    # fit the data and tag outliers\n",
    "    clf.fit(X)\n",
    "    scores_pred = clf.decision_function(X)\n",
    "    threshold = stats.scoreatpercentile(scores_pred,\n",
    "                                        100 * outliers_fraction)\n",
    "    y_pred = clf.predict(X)\n",
    "    n_errors = (y_pred != ground_truth).sum()\n",
    "    # plot the levels lines and the points\n",
    "    Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    subplot = plt.subplot(1, 3, i + 1)\n",
    "    subplot.contourf(xx, yy, Z, levels=np.linspace(Z.min(), threshold, 7),\n",
    "                        cmap=plt.cm.Blues_r)\n",
    "    a = subplot.contour(xx, yy, Z, levels=[threshold],\n",
    "                        linewidths=2, colors='red')\n",
    "    subplot.contourf(xx, yy, Z, levels=[threshold, Z.max()],\n",
    "                        colors='orange')\n",
    "    b = subplot.scatter(X[:-n_outliers, 0], X[:-n_outliers, 1], c='white')\n",
    "    c = subplot.scatter(X[-n_outliers:, 0], X[-n_outliers:, 1], c='black')\n",
    "    subplot.axis('tight')\n",
    "    subplot.legend(\n",
    "        [a.collections[0], b, c],\n",
    "        ['learned decision function', 'true inliers', 'true outliers'],\n",
    "        prop=matplotlib.font_manager.FontProperties(size=11),\n",
    "        loc='lower right')\n",
    "    subplot.set_title(\"%d. %s (errors: %d)\" % (i + 1, clf_name, n_errors))\n",
    "    subplot.set_xlim((-7, 7))\n",
    "    subplot.set_ylim((-7, 7))\n",
    "plt.subplots_adjust(0.04, 0.1, 0.96, 0.92, 0.1, 0.26)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3.7 (mimii_base_TF2_GPU)",
   "language": "python",
   "name": "mimii-tf2-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}