{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook updates the descriptive dataframe for a subsequent modeling or evaluating task. This descriptive dataframe serves as the leading input to the modeling pipeline and contains all information that is necessary to create the training and evaluating datasets.\n",
    "\n",
    "The steps within this workflow are as follows:\n",
    "\n",
    "1. accordingly to the initialized path the function loads the descriptive dataframe\n",
    "2. the function splits the instances per SNR, per machine and per ID into training and testing and creates an additional column\n",
    "3. the column is being added to the descriptive dataframe and saved back to the location\n",
    "\n",
    "To use this notebook you will have to do the following steps:\n",
    "\n",
    "1. define the path to the descriptive dataframe (path='....')\n",
    "2. run all the cells after that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T10:00:40.988108Z",
     "start_time": "2020-04-26T10:00:40.985108Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T10:00:41.299155Z",
     "start_time": "2020-04-26T10:00:41.292218Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_index(indeces, labels):\n",
    "    \n",
    "    '''\n",
    "    Will combine the testset from all abnormal operation data\n",
    "    and add up the same amount of normal operation data\n",
    "    the remaining will be the training dataset\n",
    "    \n",
    "    indeces: indeces of descriptive table or dataframe\n",
    "    labels: labels whether instance is abnormal (label==1 - abnormal)\n",
    "    '''\n",
    "\n",
    "    idx_abnormal = indeces[labels==1]\n",
    "    num_abnormal = len(idx_abnormal)\n",
    "    \n",
    "    idx_normal = indeces[labels==0]\n",
    "    idx_train, idx_test_normal = train_test_split(idx_normal, test_size=num_abnormal)\n",
    "\n",
    "    # the testset contains all abnormal operation data\n",
    "    idx_test = idx_test_normal.union(idx_abnormal)\n",
    "\n",
    "    return idx_train, idx_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T10:00:41.634395Z",
     "start_time": "2020-04-26T10:00:41.622395Z"
    }
   },
   "outputs": [],
   "source": [
    "def tt_split(table_path):\n",
    "    '''\n",
    "    Reads desciptive table from pickle, splits it into training and testing dataset.\n",
    "    Returns table with additional column with training/testing index\n",
    "    '''\n",
    "\n",
    "    table = pd.read_pickle(table_path)\n",
    "\n",
    "    SNRs = table.SNR.unique()\n",
    "    machines = table.machine.unique()\n",
    "    IDs = table.ID.unique()\n",
    "\n",
    "    if 'train_set' in table.columns:\n",
    "\n",
    "        return 'Train test split already done'\n",
    "\n",
    "    else:\n",
    "\n",
    "        # initialize the new column\n",
    "        tt_series = pd.Series(0, index=table.index,\n",
    "                              name='train_set', dtype=np.int8)\n",
    "\n",
    "        # split for every individual ID, machine and SNR\n",
    "        for SNR in SNRs:\n",
    "            for machine in machines:\n",
    "                for ID in IDs:\n",
    "\n",
    "                    # create the individual mask \n",
    "                    # and read the indeces and labels accordingly\n",
    "                    mask = (table.SNR == SNR) & (\n",
    "                        table.machine == machine) & (table.ID == ID)\n",
    "                    \n",
    "                    idx = table[mask].index\n",
    "                    labels = table[mask].abnormal\n",
    "\n",
    "                    # get the indeces that belong to the training dataset \n",
    "                    # and update the new column\n",
    "                    idx_train, _ = split_index(idx, labels)\n",
    "                    tt_series[idx_train] = 1\n",
    "\n",
    "        table = table.join(tt_series)\n",
    "        table.to_pickle(table_path)\n",
    "\n",
    "        return 'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T10:00:42.021335Z",
     "start_time": "2020-04-26T10:00:42.005392Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Train test split already done'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '.\\..\\..\\dataset\\MEL_to_Pandas\\data\\pandas_pump_6dB_00020406_MEL_v1_64.pkl'\n",
    "tt_split(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T10:00:42.077333Z",
     "start_time": "2020-04-26T10:00:42.067328Z"
    }
   },
   "outputs": [],
   "source": [
    "table = pd.read_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T10:00:43.178811Z",
     "start_time": "2020-04-26T10:00:43.171989Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int8)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table[table.abnormal==1].train_set.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3.7 (mimii_base_TF2_GPU)",
   "language": "python",
   "name": "mimii-tf2-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
